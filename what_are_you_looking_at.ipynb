{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input, InceptionResNetV2\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "# import PIL\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "config = tensorflow.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "sess = tensorflow.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "# Select a model to use, in this case VGG16\n",
    "model = InceptionResNetV2(weights='imagenet', include_top=True, input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "# Check with 'print(model.summary())', in this case it is \"block5_conv3\"\n",
    "last_conv_layer_name = \"conv_7b\"\n",
    "# Must include layers between last convolutional layer and prediction layer\n",
    "# Layer names can be found through 'print(model.summary())'\n",
    "classifier_layer_names = [\"conv_7b_bn\", \"conv_7b_ac\", \"avg_pool\", \"predictions\"]\n",
    "\n",
    "\n",
    "# This function is called from 'make_gradcam_heatmap'\n",
    "# Takes iaage_path from 'get_command_line_arguments', turns into it an array\n",
    "def get_img_array(img_path, size):\n",
    "    img = tensorflow.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
    "    # `array` is a float32 Numpy array\n",
    "    array = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "model = InceptionResNetV2()\n",
    "\n",
    "\n",
    "# 'make_gradcam_heatmap' is main function and ultimately returns heatmap superimposed onto the input image(s)\n",
    "\n",
    "# inputs are the image path specified in the command line, the last convolutional layer and\n",
    "# the classifier layer names of which both are defined above and depend on your model, and the output path\n",
    "# for our heatmap superimposed onto original image which are specified in the script's final if statement\n",
    "def make_gradcam_heatmap(\n",
    "        img_path, model, last_conv_layer_name, classifier_layer_names, output_path\n",
    "):\n",
    "    # pre_processes the array returned from 'get_img_array'\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=(299, 299)))\n",
    "\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = tensorflow.keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tensorflow.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = tensorflow.keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tensorflow.GradientTape() as tape:\n",
    "\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tensorflow.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tensorflow.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "    # We load the original image\n",
    "    img = tensorflow.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # We rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tensorflow.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tensorflow.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * 0.4 + img\n",
    "    # superimposed_img = cv2.imdecode(superimposed_img, cv2.IMREAD_UNCHANGED)\n",
    "    # superimposed_img = tensorflow.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Test to write something on top of image with OpenCV\n",
    "    # superimposed_img = cv2.imread(superimposed_img)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    pred_class = tensorflow.keras.applications.vgg16.decode_predictions(predictions, top=1)[0][0][1]\n",
    "    pred_conf = tensorflow.keras.applications.vgg16.decode_predictions(predictions, top=1)[0][0][2]\n",
    "\n",
    "    position_class = (10, 50)\n",
    "    position_confidence = (10, 100)\n",
    "    cv2.putText(\n",
    "        superimposed_img,\n",
    "        pred_class,\n",
    "        position_class,\n",
    "        cv2.FONT_ITALIC,\n",
    "        1,\n",
    "        (0, 0, 0, 255),\n",
    "        3\n",
    "    )\n",
    "    cv2.putText(\n",
    "        superimposed_img,\n",
    "        str(np.around(pred_conf, 2)),\n",
    "        position_confidence,\n",
    "        cv2.FONT_ITALIC,\n",
    "        1,\n",
    "        (0, 0, 0, 255),\n",
    "        3\n",
    "    )\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
    "    # Save the the superimposed image to the output path\n",
    "    # superimposed_img.save(output_path)\n",
    "\n",
    "\n",
    "# Runs body of code for entirety of videoframs_path (folder specified in command line)\n",
    "def process_video(videoframes_path, output_prefix):\n",
    "    counter = 0\n",
    "    # define output directory\n",
    "    output_dir = output_prefix + \"_output\"\n",
    "\n",
    "    # Creates directory output directoy if it doesn't already exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for input_path in sorted(glob.glob(videoframes_path + \"/*.jpg\")):\n",
    "        counter += 1\n",
    "\n",
    "        output_path = output_dir + \"/result-inceptionv4-\" + str(counter).zfill(6) + '.jpg'\n",
    "\n",
    "        # Runs main function with specified image_path, output_prefix, and layers defined near top of script\n",
    "        make_gradcam_heatmap(input_path, model, last_conv_layer_name, classifier_layer_names, output_path)\n",
    "\n",
    "\n",
    "# Function for taking inputs through the command line\n",
    "def get_command_line_arguments():\n",
    "    parser = ArgumentParser()\n",
    "    # We specify either image or video to\n",
    "    parser.add_argument(\"--process\", choices=[\"image\", \"video\"], required=True,\n",
    "                        dest=\"process_type\", help=\"Process a single image or video\")\n",
    "    parser.add_argument(\"--path\", required=True, dest=\"path\",\n",
    "                        help=\"Path of image or directory containing video frames\")\n",
    "    return parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl 'https://images.theconversation.com/files/319375/original/file-20200309-118956-1cqvm6j.jpg' --output \"perrito.jpg\"\n",
    "\n",
    "process_type = \"image\"\n",
    "\n",
    "# If process is specified as 'image', defines image_path and output_prefix according to command line argument\n",
    "if process_type == \"image\":\n",
    "    # image path is location of image that we want to generate a heatmap for\n",
    "    image_path = 'perrito.jpg'\n",
    "    output_prefix = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    # Runs main function with specified image_path and output_prefix from command line\n",
    "    # layers defined near top of script\n",
    "    make_gradcam_heatmap(image_path, model, last_conv_layer_name, classifier_layer_names, output_prefix + \"_output.jpg\")\n",
    "\n",
    "    # Plot the superimposed image\n",
    "    img = mpimg.imread(output_prefix + \"_output.jpg\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# If process is specified as 'image', defines videoframes_path and output_prefix according to command line argument\n",
    "elif process_type == \"video\":\n",
    "    # videoframes_path is directory with the video frames split by ffmpeg\n",
    "    videoframes_path = args.path\n",
    "    # will be used to specify or create output folder\n",
    "    output_prefix = os.path.dirname(videoframes_path)\n",
    "    # Runs 'process_video' function with inputs taken from command line\n",
    "    heatmaps = process_video(videoframes_path, output_prefix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
